{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmu6MDFeNhw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "56f1a204-2759-46c8-8613-629aae2e142b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9c04846328e1>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/object_detection/utils/label_map_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'string_int_label_map_pb2' from 'object_detection.protos' (/usr/local/lib/python3.10/dist-packages/object_detection/protos/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "import sys\n",
        "\n",
        "import datetime\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "import PIL\n",
        "\n",
        "from PIL import ImageOps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Activation, ReLU\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose, Concatenate\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image\n",
        "\n",
        "\n",
        "os.system('kaggle datasets download -d sshikamaru/car-object-detection')\n",
        "\n",
        "\n",
        "num_classes = 6\n",
        "batch_size = 10\n",
        "img_size = (160, 160)\n",
        "\n",
        "\n",
        "image_list = \"Public_Testing_Dataset_Only_for _detection\"\n",
        "save_dir = \".\"\n",
        "\n",
        "#print (image_list)\n",
        "#print (save_dir)\n",
        "\n",
        "\n",
        "import shutil\n",
        "\n",
        "os.mkdir(save_dir+\"/object_detections\")\n",
        "os.mkdir(save_dir+\"/segmentation\")\n",
        "#model = tf.keras.models.load_model('tensorflow_model')\n",
        "import zipfile\n",
        "\n",
        "import pathlib\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "filename = []\n",
        "filesc = []\n",
        "fileclass = []\n",
        "filex = []\n",
        "filey = []\n",
        "filew = []\n",
        "fileh = []\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "batch_size = 32\n",
        "j = 0\n",
        "submit2=pd.DataFrame()\n",
        "y = 0\n",
        "\n",
        "\n",
        "DETECTION_THRESHOLD = 0.3\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model_path = 'model.tflite/model.tflite'\n",
        "\n",
        "# Load the labels into a list\n",
        "classes = ['???'] * 1000\n",
        "label_map = open('model.tflite/labelmap.txt','r')\n",
        "label_line = label_map.readlines()\n",
        "t = 0\n",
        "for label_name in label_line:\n",
        "    classes[t] = label_name\n",
        "    t = t+1\n",
        "# Define a list of colors for visualization\n",
        "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
        "\n",
        "def preprocess_image(image_path, input_size):\n",
        "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, np.float32)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  resized_img = tf.cast(resized_img, dtype=np.float32)\n",
        "  return resized_img, original_image\n",
        "\n",
        "def detect_objects(interpreter, image, threshold):\n",
        "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
        "\n",
        "  signature_fn = interpreter.get_signature_runner()\n",
        "\n",
        "  # Feed the input image to the model\n",
        "  output = signature_fn(input=image)\n",
        "\n",
        "  # Get all outputs from the model\n",
        "  count = int(np.squeeze(output['output_0']))\n",
        "  scores = np.squeeze(output['output_1'])\n",
        "  classes = np.squeeze(output['output_2'])\n",
        "  boxes = np.squeeze(output['output_3'])\n",
        "\n",
        "  results = []\n",
        "  for i in range(count):\n",
        "    if scores[i] >= threshold:\n",
        "      result = {\n",
        "        'bounding_box': boxes[i],\n",
        "        'class_id': classes[i],\n",
        "        'score': scores[i]\n",
        "      }\n",
        "      results.append(result)\n",
        "  return results\n",
        "\n",
        "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
        "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
        "  # Load the input shape required by the model\n",
        "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
        "\n",
        "  # Load the input image and preprocess it\n",
        "  preprocessed_image, original_image = preprocess_image(\n",
        "      image_path,\n",
        "      (input_height, input_width)\n",
        "    )\n",
        "\n",
        "  # Run object detection on the input image\n",
        "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
        "\n",
        "  # Plot the detection results on the input image\n",
        "  original_image_np = original_image.numpy().astype(np.uint8)\n",
        "  for obj in results:\n",
        "    # Convert the object bounding box from relative coordinates to absolute\n",
        "    # coordinates based on the original image resolution\n",
        "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
        "    xmin = int(xmin * original_image_np.shape[1])\n",
        "    xmax = int(xmax * original_image_np.shape[1])\n",
        "    ymin = int(ymin * original_image_np.shape[0])\n",
        "    ymax = int(ymax * original_image_np.shape[0])\n",
        "    filex.append(int(xmin))\n",
        "    filey.append(int(ymin))\n",
        "    fileh.append(int(ymax-ymin))\n",
        "    filew.append(int(xmax-xmin))\n",
        "    filename.append(line)\n",
        "    # Find the class index of the current object\n",
        "    class_id = int(obj['class_id'])\n",
        "    #print(class_id)\n",
        "    if(class_id == 0):\n",
        "        fileclass.append(2)\n",
        "    elif(class_id == 1):\n",
        "        fileclass.append(4)\n",
        "    elif(class_id == 3):\n",
        "        fileclass.append(3)\n",
        "    elif(class_id == 7):\n",
        "        fileclass.append(1)\n",
        "    elif(class_id == 5):\n",
        "        fileclass.append(1)\n",
        "    elif(class_id == 2):\n",
        "        fileclass.append(1)\n",
        "    else:\n",
        "        fileclass.append('x')\n",
        "    filesc.append(obj['score'])\n",
        "    # Draw the bounding box and label on the image\n",
        "    color = [int(c) for c in COLORS[class_id]]\n",
        "    cv.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "    # Make adjustments to make the label visible for all objects\n",
        "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
        "    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\n",
        "    cv.putText(original_image_np, label, (xmin, y),\n",
        "        cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "  # Return the final image\n",
        "  original_uint8 = original_image_np.astype(np.uint8)\n",
        "  return original_uint8\n",
        "\n",
        "\n",
        "#model_path2 = 'model.tflite/model_only.tflite'\n",
        "\n",
        "\n",
        "def preprocess_image(image_path, input_size):\n",
        "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
        "  img = tf.io.read_file(image_path)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, np.float32)\n",
        "  original_image = img\n",
        "  resized_img = tf.image.resize(img, input_size)\n",
        "  resized_img = resized_img[tf.newaxis, :]\n",
        "  resized_img = tf.cast(resized_img, dtype=np.float32)\n",
        "  return resized_img, original_image\n",
        "\n",
        "i=0\n",
        "for line in os.listdir(image_list+\"/\"):\n",
        "    #try:\n",
        "        image_np = cv.imread(image_list+\"/\"+line)\n",
        "        images = line.split(\".\")\n",
        "        image_n = cv.resize(image_np[:,:,::-1], # Resizing the mapped image to the original image size.\n",
        "                                           (160,\n",
        "                                            160))\n",
        "\n",
        "        image_n = np.expand_dims(image_n,axis=0)\n",
        "\n",
        "\n",
        "        #val_preds = model.predict(image_n)\n",
        "        #mask = np.argmax(val_preds[0], axis=-1)\n",
        "        #print(val_preds)\n",
        "        #mask = np.expand_dims(mask, axis=-1)\n",
        "        #cv.imencode(\".png\",mask.astype(np.int32))[1].tofile(save_dir+\"/segmentation/\"+images[0]+'.png')\n",
        "        #img = cv.imread(save_dir+\"/segmentation/\"+images[0]+'.png',-1)\n",
        "        #img = cv.resize(img, (1920, 1080),cv.INTER_CUBIC)\n",
        "\n",
        "        #print(*np.array(img))\n",
        "        #cv.imwrite(save_dir+\"/segmentation/\"+images[0]+'.png',img)\n",
        "\n",
        "\n",
        "        new_img = cv.resize(image_np, (512, 512),cv.INTER_CUBIC)\n",
        "        new_img_1 = new_img\n",
        "        DETECTION_THRESHOLD = 0.3\n",
        "\n",
        "        interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "        interpreter.allocate_tensors()\n",
        "        signatures = interpreter.get_signature_list()\n",
        "        #print(signatures)\n",
        "\n",
        "        input_details = interpreter.get_input_details()\n",
        "        output_details = interpreter.get_output_details()\n",
        "        print('INPUT\\n', input_details)\n",
        "        print('\\n OUTPUT\\n',output_details)\n",
        "\n",
        "        detection_result_image = run_odt_and_draw_results(\n",
        "                line[0],\n",
        "                interpreter,\n",
        "                threshold=DETECTION_THRESHOLD\n",
        "        )\n",
        "        cv.imwrite(save_dir+\"/object_detections/\"+images[0]+'.png',detection_result_image)\n",
        "    #except:\n",
        "        y = y+1\n",
        "        #print(\"error\")\n",
        "submit2.insert(0,column=\"confidence\",value=filesc)\n",
        "submit2.insert(0,column=\"h\",value=fileh)\n",
        "submit2.insert(0,column=\"w\",value=filew)\n",
        "submit2.insert(0,column=\"y\",value=filey)\n",
        "submit2.insert(0,column=\"x\",value=filex)\n",
        "submit2.insert(0,column=\"label_id\",value=fileclass)\n",
        "submit2.insert(0,column=\"image_filename\",value=filename)\n",
        "\n",
        "submit2.to_csv(save_dir+\"/object_detections/submission.csv\",index=False)\n",
        "os.chdir(save_dir)\n",
        "#with zipfile.ZipFile('submission.zip', mode='w') as zf:\n",
        "    # 將要壓縮的檔案加入\n",
        "    #zf.write(\"object_detections/submission.csv\")\n",
        "#    for root, dirs, files in os.walk(\"segmentation\"):\n",
        "#        for file_name in files:\n",
        "#            zf.write(os.path.join(root, file_name))\n",
        "#shutil.rmtree(\"object_detections\")\n",
        "#shutil.rmtree(\"segmentation\")\n",
        "f.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}